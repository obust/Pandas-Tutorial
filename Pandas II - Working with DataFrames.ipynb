{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas II - Working with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the [MovieLens](http://www.grouplens.org/node/73) dataset in many examples going forward. The dataset contains 100,000 ratings made by 943 users on 1,682 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "df_users = pd.read_csv('data/MovieLens-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "df_ratings = pd.read_csv('data/MovieLens-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "df_movies = pd.read_csv('data/MovieLens-100k/u.item', sep='|', names=m_cols, usecols=range(5))# only load the first five columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. [Inspect](#1.-Inspect)<br>\n",
    "    a) .dtype<br>\n",
    "    b) .describe()<br>\n",
    "    c) .head(), .tail(), [i:j]\n",
    "2. [Select](#2.-Select)<br>\n",
    "    a) Column Selection<br>\n",
    "    b) Row Selection<br>\n",
    "3. [Sort](#3.-Sort)<br>\n",
    "    a) .sort() for DataFrames<br>\n",
    "    b) .order() for Series<br>\n",
    "4. [Operations](#4.-Operations)<br>\n",
    "    a) Descriptive Stats<br>\n",
    "    b) Apply<br>\n",
    "    b) Bins<br>\n",
    "    b) Histograms<br>\n",
    "5. [Split-Apply-Combine](#5.-Split-Apply-Combine)\n",
    "6. [Merge](#6.-Merge)<br>\n",
    "    a) Inner Join (default)<br>\n",
    "    b) Left Outer Join<br>\n",
    "    c) Right Outer Join<br>\n",
    "    d) Full Outer Join<br>\n",
    "7. [Concatenate](#7.-Concatenate)\n",
    "8. [Other](#8.-Other)<br>\n",
    "    a) Rename columns<br>\n",
    "    b) Missing values<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect\n",
    "\n",
    "Pandas has a variety of functions for getting basic information about your DataFrame.<br>\n",
    "The most basic of which is **calling your DataFrame by name**. The output tells a few things about our DataFrame.\n",
    "\n",
    "1. It's an instance of a DataFrame.\n",
    "2. Each row is assigned an index of 0 to N-1, where N is the number of rows in the DataFrame. (index can be set arbitrary)\n",
    "3. There are 1,682 rows (every row must have an index).\n",
    "4. Our dataset has five total columns, one of which isn't populated at all (video_release_date) and two that are missing some values (release_date and imdb_url)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)  `.dtypes`\n",
    "Use the `.dtypes` attribute to get the datatype for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                int64\n",
      "title                  object\n",
      "release_date           object\n",
      "video_release_date    float64\n",
      "imdb_url               object\n",
      "dtype: object \n",
      "\n",
      "user_id        int64\n",
      "age            int64\n",
      "sex           object\n",
      "occupation    object\n",
      "zip_code      object\n",
      "dtype: object \n",
      "\n",
      "user_id           int64\n",
      "movie_id          int64\n",
      "rating            int64\n",
      "unix_timestamp    int64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print df_movies.dtypes,'\\n'\n",
    "\n",
    "print df_users.dtypes,'\\n'\n",
    "\n",
    "print df_ratings.dtypes,'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) `.describe()`\n",
    "Use the `.describe()` method to see the basic statistics about the DataFrame's **numeric columns**. Be careful though, since this will return information on **all** columns of a numeric datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>34.051962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>272.364951</td>\n",
       "      <td>12.192740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>236.500000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>707.500000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id         age\n",
       "count  943.000000  943.000000\n",
       "mean   472.000000   34.051962\n",
       "std    272.364951   12.192740\n",
       "min      1.000000    7.000000\n",
       "25%    236.500000   25.000000\n",
       "50%    472.000000   31.000000\n",
       "75%    707.500000   43.000000\n",
       "max    943.000000   73.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `user_id` was included since it's numeric. Since this is an ID value, the stats for it don't really matter.\n",
    "\n",
    "We can quickly see the average age of our users is just above 34 years old, with the youngest being 7 and the oldest being 73. The median age is 31, with the youngest quartile of users being 25 or younger, and the oldest quartile being at least 43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) `.head(), tail(), [i:j]`\n",
    "By default, **`.head()`** displays the first five records of the DataFrame, while **`.tail()`** displays the last five.<br>\n",
    "Alternatively, Python's regular slicing **`[i:j]`** syntax works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n"
     ]
    }
   ],
   "source": [
    "print df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  age sex occupation zip_code\n",
      "940      941   20   M    student    97229\n",
      "941      942   48   F  librarian    78209\n",
      "942      943   22   M    student    77841\n"
     ]
    }
   ],
   "source": [
    "print df_users.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  age sex occupation zip_code\n",
      "20       21   26   M     writer    30068\n",
      "21       22   25   M     writer    40206\n"
     ]
    }
   ],
   "source": [
    "print df_users[20:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select\n",
    "\n",
    "### a) Column Selection\n",
    "\n",
    "You can think of a DataFrame as a group of Series (ie: rows) that share an index (ie: column headers). This makes it easy to select specific columns.\n",
    "\n",
    "**Single column selection**<br>\n",
    "Selecting a single column from the DataFrame will return a **Series object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    technician\n",
       "1         other\n",
       "2        writer\n",
       "3    technician\n",
       "4         other\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users['occupation'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple columns selection**<br>\n",
    "To select multiple columns, simply pass a **list of column names** to the DataFrame, the output of which will be a **DataFrame**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   occupation sex\n",
      "0  technician   M\n",
      "1       other   F\n",
      "2      writer   M\n",
      "3  technician   M\n",
      "4       other   F\n"
     ]
    }
   ],
   "source": [
    "list_of_cols = ['occupation', 'sex'] \n",
    "print df_users[list_of_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Row Selection\n",
    "Row selection can be done [multiple ways](http://pandas.pydata.org/pandas-docs/stable/indexing.html), but using **boolean indexing** or **individual index `.ix()`** are typically easiest.\n",
    "\n",
    "#### Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex occupation zip_code\n",
      "1        2   53   F      other    94043\n",
      "4        5   33   F      other    15213\n",
      "5        6   42   M  executive    98101 \n",
      "\n",
      "     user_id  age sex  occupation zip_code\n",
      "18        19   40   M   librarian    02138\n",
      "82        83   40   M       other    44133\n",
      "115      116   40   M  healthcare    97232 \n",
      "\n",
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n"
     ]
    }
   ],
   "source": [
    "# users older than 25\n",
    "print df_users[df_users.age > 25].head(3), '\\n'\n",
    "\n",
    "# users aged 40 AND male\n",
    "print df_users[(df_users.age == 40) & (df_users.sex == 'M')].head(3), '\\n'\n",
    "\n",
    "# users younger than 30 OR female\n",
    "print df_users[(df_users.sex == 'F') | (df_users.age < 30)].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.ix()` method\n",
    "\n",
    "When you change the indexing of a DataFrame to a specific column, you use the default pandas 0-based index.<br>\n",
    "Use **`.ix()`** method for row selection based on the new index.\n",
    "\n",
    "Let's set the index to the `user_id` using the **`.set_index()`** method.<br>\n",
    "NB: By default, `.set_index()` returns a new DataFrame, so you'll have to specify if you'd like the changes to occur in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "2         53   F       other    94043\n",
      "3         23   M      writer    32067\n",
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "2         53   F       other    94043\n",
      "3         23   M      writer    32067\n"
     ]
    }
   ],
   "source": [
    "# Change index column (new DataFrame)\n",
    "new_df_users = df_users.set_index('user_id')\n",
    "print new_df_users.head(3)\n",
    "\n",
    "# Change index column (inplace)\n",
    "df_users.set_index('user_id', inplace=True)\n",
    "print df_users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                20\n",
      "sex                 M\n",
      "occupation    student\n",
      "zip_code        63129\n",
      "Name: 99, dtype: object \n",
      "\n",
      "         age sex  occupation zip_code\n",
      "user_id                              \n",
      "1         24   M  technician    85711\n",
      "50        21   M      writer    52245\n",
      "300       26   F  programmer    55106\n"
     ]
    }
   ],
   "source": [
    "# Select users using their respective user_id\n",
    "print df_users.ix[99], '\\n'\n",
    "print df_users.ix[[1, 50, 300]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **`.reset_index()`** method to reset the default index (the same rule apply for inplace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n"
     ]
    }
   ],
   "source": [
    "df_users.reset_index(inplace=True)\n",
    "print df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort\n",
    "\n",
    "### a) `.sort()` for DataFrames\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort.html<br>\n",
    "Use **`.sort()`** method to sort DataFrames. Returns a new instance of a Dataframe.\n",
    "\n",
    ">- `column` : column name to base the sorting on (list for nested sorting / tuple for multi-index sorting)\n",
    ">- `ascending (True)` : sort ascending vs. descending (specify list for multiple sort orders)\n",
    ">- `inplace (False)`: result is a new instance of DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  age sex  occupation zip_code\n",
      "196      197   55   M  technician    75094\n",
      "440      441   50   M  technician    55013\n",
      "487      488   48   M  technician    21012\n",
      "324      325   48   M  technician    02139\n",
      "457      458   47   M  technician    Y1A6B\n"
     ]
    }
   ],
   "source": [
    "# Oldest techicians\n",
    "df_users.sort('age', ascending=False, inplace=True)\n",
    "print df_users[df_users.occupation == \"technician\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) `.order()` for Serie\n",
    "\n",
    "Use **`.order()`** method to sort Series. Returns a new instance of a Dataframe.\n",
    "\n",
    ">- `ascending (True)` : sort ascending vs. descending (specify list for multiple sort orders)\n",
    ">- `inplace (False)`: result is a new instance of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185    00000\n",
      "766    00000\n",
      "8      01002\n",
      "Name: zip_code, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_users.zip_code.order()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operations\n",
    "\n",
    "### a) Descriptive Stats\n",
    "\n",
    "A large number of methods for computing descriptive statistics and other related operations on Series, DataFrame, and Panel. For DataFrames these methods take an axis argument:\n",
    ">- axis=0 : compute over indexes\n",
    ">- axis=1 : compute over columns\n",
    "\n",
    "Most methods produce a lower-dimensional result :\n",
    "- `.count()`: number of NOT NULL values\n",
    "- `.nunique()`: number of unique NOT NULL values\n",
    "- `.size()` : number of values\n",
    "- `.min()`:\tminimum\n",
    "- `.max()`:\tmaximum\n",
    "- `.sum()`:\tsum of values\n",
    "- `.prod()`: product of values\n",
    "- `.median()`: arithmetic median of values\n",
    "- `.quantile()`: sample quantile (value at %)\n",
    "- `.mean()`: mean of values\n",
    "- `.std()`:\tunbiased standard deviation\n",
    "- `.var()`:\tunbiased variance\n",
    "- `.mad()`:\tmean absolute deviation\n",
    "- `.sem()`:\tunbiased standard error of the mean\n",
    "- `.skew()`: unbiased skewness (3rd moment)\n",
    "- `.kurt()`: unbiased kurtosis (4th moment)\n",
    "\n",
    "Some methods produce an object of the same size :\n",
    "- `.rank()`: compute data rank (1 through n)\n",
    "- `.mode()`: mode\n",
    "- `.abs()`:\tabsolute value\n",
    "- `.cumsum()`: cumulative sum\n",
    "- `.cumprod()`: cumulative product\n",
    "- `.cummax()`: cumulative maximum\n",
    "- `.cummin()`: cumulative minimum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Apply\n",
    "\n",
    "To apply **your own or another libraryâ€™s functions** to pandas objects, you should be aware of the three methods below. The appropriate method to use depends on whether your function expects to operate on an entire DataFrame or Series, row- or column-wise, or elementwise.\n",
    "\n",
    "- Tablewise Function Application: **`.pipe()`**\n",
    "- Row or Column-wise Function Application: **`.apply()`**\n",
    "- Elementwise function application: **`.applymap()`** or **`.map()`**\n",
    "\n",
    "#### `.pipe()`\n",
    "Use `.pipe()` for method chaining **over a DataFrame**. (See [DOC](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pipe.html))<br>\n",
    "The following two are equivalent :\n",
    "    - f(g(h(df), arg1=1), arg2=2, arg3=3)\n",
    "    - df.pipe(h).pipe(g, arg1=1).pipe(f, arg2=2, arg3=3)\n",
    "The pipe method is inspired by unix pipes and more recently dplyr and magrittr, which have introduced the popular (%>%) (read pipe) operator for R.\n",
    "\n",
    "#### `.apply()`\n",
    "Use `.apply()` to apply a function **along the axes** of a DataFrame, like the descriptive statistics methods. (See [DOC](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html))<br>\n",
    "\n",
    "    - df.apply(np.mean, axis=1)\n",
    "    - df.apply(lambda x: x.max() - x.min())\n",
    "\n",
    "#### `.applymap()`\n",
    "Use `.applymap()` on DataFrame or `.map()` on Series to **operate elementwise**.<br>\n",
    "The vectorized function must take a single value and return a single value.(See [DOC](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.applymap.html))<br>\n",
    "\n",
    "    - df.applymap(lambda x: len(str(x)))\n",
    "    - df['colA'].map(lambda x: len(str(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bins\n",
    "\n",
    "Use **`pandas.cut()`** static method to bin numeric values into groups. Useful for discretization. ([DOC](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html))\n",
    "\n",
    "`pandas.cut(x, bins)` returns an array of the indices (or labels) of the half-open bins to which each value of `x` belongs.\n",
    "\n",
    ">- `x` : array of values to be binned\n",
    ">- `bins` : sequence defining the bin edges\n",
    ">- `right` (True): boolean indicating whether the bins include the rightmost edge or not ([a,b] or [a,b[)\n",
    ">- `labels` (None): array used as labels for the resulting bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  age sex  occupation zip_code age_group\n",
      "930      931   60   M    educator    33556     60-69\n",
      "693      694   60   M  programmer    06365     60-69\n",
      "751      752   60   M     retired    21201     60-69\n",
      "89        90   60   M    educator    78155     60-69\n"
     ]
    }
   ],
   "source": [
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "bins = range(0, 81, 10) # [0, 10, 20, 30, 40, 50, 60, 70, 80]\n",
    "df_users['age_group'] = pd.cut(df_users.age, bins, right=False, labels=labels)\n",
    "print df_users[27:31] # preview of age bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Histograms\n",
    "\n",
    "Use **`.value_counts()`** Series method to return the **counts** of **unique values** (ie frequency). (See [DOC](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html#pandas.Series.value_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student          196\n",
       "other            105\n",
       "educator          95\n",
       "administrator     79\n",
       "engineer          67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users['occupation'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split-Apply-Combine\n",
    "\n",
    "Pandas **`.groupby()`** method uses the [split-apply-combine strategy](http://www.jstatsoft.org/v40/i01/paper) for data analysis :\n",
    "1. **Split** the DataFrame into groups based on some criteria (DataFrameGroupBy or SeriesGroupBy)\n",
    "2. **Apply** a function to each group independently\n",
    "3. **Combine** the results into a data structure (DataFrame or Series)\n",
    "\n",
    "![split-apply-combine-methodology](http://nbviewer.ipython.org/github/umddb/datascience-fall14/blob/master/lab3/img/splitApplyCombine.png)\n",
    "\n",
    "In the apply step, we might wish to do one of the following:\n",
    "- **Aggregation**: computing a summary statistic (or statistics) about each group. Some examples:\n",
    "    - Compute group columns sums and means : \n",
    "        - `gby.agg([np.sum, np.mean])`\n",
    "    - Compute group sizes and counts : \n",
    "        - `gby.agg([np.size, np.mean])`\n",
    "- **Transformation**: perform some group-specific computations on every data point. Some examples:\n",
    "    - Standardizing data (zscore) within group : \n",
    "        - `gby.transform(lambda x: (x - x.mean()) / x.std())`\n",
    "    - Filling NAs within groups with a value derived from each group\n",
    "        - `gby.fillna(x.mean())`\n",
    "- **Filtration**: discard some groups, according to a group-wise computation that evaluates True or False. Some examples:\n",
    "    - Discarding data that belongs to groups with only a few members : \n",
    "        - `gby.filter(lambda x: x.size() > 100)`\n",
    "    - Discarding data based on the group sum or mean\n",
    "        - `gby.filter(lambda x: x['A'].sum() + x['B'].sum() > 0)`\n",
    "    - Discarding data for missing data\n",
    "        - `gby.dropna(axis=0)`\n",
    "\n",
    "pandas **`.groupby()`** returns a DataFrameGroupBy or SeriesGroupBy object which has a variety of methods.<br>\n",
    "http://pandas.pydata.org/pandas-docs/stable/api.html#id35\n",
    "\n",
    "**DataFrameGroupBy/SeriesGroupBy Methods**\n",
    "- `.apply()`: apply function or list of functions\n",
    "- `.agg()`: aggregate using input function or dict of {column: function}\n",
    "- `.filter()`: returns a copy of a DataFrame excluding elements from groups that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City of Chicago salaries\n",
    "The City of Chicago is kind enough to publish all city employee salaries to its open data portal. Let's go through some basic `groupby` examples using this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Position Title,Department,Employee Annual Salary\r\n",
      "\"AARON,  ELVIA J\",WATER RATE TAKER,WATER MGMNT,$85512.00\r\n",
      "\"AARON,  JEFFERY M\",POLICE OFFICER,POLICE,$75372.00\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 data/city-of-chicago-salaries.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data contains a '$' sign for each salary, python will treat the field as a series of strings. We can use the `converters` parameter to change this when reading in the file.\n",
    "\n",
    "> `converters` = Dict of functions for converting values in certain columns. Keys can either be integers or column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name                     title        department  salary\n",
      "0        AARON,  ELVIA J          WATER RATE TAKER       WATER MGMNT   85512\n",
      "1      AARON,  JEFFERY M            POLICE OFFICER            POLICE   75372\n",
      "2    AARON,  KIMBERLEI R  CHIEF CONTRACT EXPEDITER  GENERAL SERVICES   80916\n",
      "3    ABAD JR,  VICENTE M         CIVIL ENGINEER IV       WATER MGMNT   99648\n",
      "4  ABBATACOLA,  ROBERT J       ELECTRICAL MECHANIC          AVIATION   89440\n"
     ]
    }
   ],
   "source": [
    "headers = ['name', 'title', 'department', 'salary']\n",
    "df_chicago = pd.read_csv('data/city-of-chicago-salaries.csv',\n",
    "                      header=False,\n",
    "                      names=headers,\n",
    "                      converters={'salary': lambda x: float(x.replace('$', ''))})\n",
    "print df_chicago.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  title  salary\n",
      "department                        \n",
      "ADMIN HEARNG     42     42      42\n",
      "ANIMAL CONTRL    61     61      61\n",
      "AVIATION       1218   1218    1218 \n",
      "\n",
      "department\n",
      "ADMIN HEARNG       42\n",
      "ANIMAL CONTRL      61\n",
      "AVIATION         1218\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df_chicago.groupby('department').count().head(3), '\\n' # NOT NULL records within each column\n",
    "print df_chicago.groupby('department').size().head(3) # total records for each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  salary              \n",
      "                    size          mean\n",
      "department                            \n",
      "ADMIN HEARNG          42  70336.857143\n",
      "ANIMAL CONTRL         61  57121.455738\n",
      "AVIATION            1218  70638.249130\n",
      "BOARD OF ELECTION    110  55728.872727\n",
      "BOARD OF ETHICS        9  81650.666667\n"
     ]
    }
   ],
   "source": [
    "print df_chicago.groupby('department').agg({'salary': [np.size, np.mean]}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What departments have the most number of distinct title positions ?\n",
    "\n",
    "1. Split DataFrame into groups by departement, keep only title column => **SeriesGroupBy**\n",
    "2. Apply `.nunique()` method\n",
    "3. (Combine into **Serie**)\n",
    "4. Order resulting **Serie** (NB: `.order()` is for Series, `.sort()` is for DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "WATER MGMNT    153\n",
      "TRANSPORTN     150\n",
      "POLICE         130\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df_chicago.groupby('department').title.nunique().order(ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What department pays best on average ?\n",
    "\n",
    "1. Split DataFrame into groups by departement => **DataFrameGroupBy**\n",
    "2. Apply `.mean()` method\n",
    "3. (Combine into **DataFrame**)\n",
    "4. Sort resulting **DataFrame** according to the salary (NB: `.order()` is for Series, `.sort()` is for DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      salary\n",
      "department                  \n",
      "DoIT            93209.939394\n",
      "BUILDINGS       90720.081322\n",
      "FIRE            89579.082621\n",
      "MAYOR'S OFFICE  85251.949091\n",
      "BUDGET & MGMT   84767.181818\n"
     ]
    }
   ],
   "source": [
    "print df_chicago.groupby('department').mean().sort('salary', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               salary              \n",
      "                 size          mean\n",
      "department                         \n",
      "DoIT               99  93209.939394\n",
      "BUILDINGS         242  90720.081322\n",
      "FIRE             4731  89579.082621\n",
      "MAYOR'S OFFICE     99  85251.949091\n",
      "BUDGET & MGMT      44  84767.181818\n"
     ]
    }
   ],
   "source": [
    "print df_chicago.groupby('department').agg({'salary': [np.size, np.mean]}).sort(('salary', 'mean'), ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is the highest paid employee of each department ?\n",
    "\n",
    "1. Split DataFrame into groups by departement, keep only salary column => **SeriesGroupBy**\n",
    "2. Apply `.rank()` method\n",
    "3. (Combine into **Serie**)\n",
    "4. Assign the resulting Serie to a new column of the DataFrame\n",
    "5. Sort DataFrame according to salary (NB: `.order()` is for Series, `.sort()` is for DataFrames)\n",
    "6. Display only first rankers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `.rank()` method, use attribute method='first' so that equally high paid people within a department don't get the same rank ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name                     title      department  \\\n",
      "18039     MC CARTHY,  GARRY F  SUPERINTENDENT OF POLICE          POLICE   \n",
      "8004           EMANUEL,  RAHM                     MAYOR  MAYOR'S OFFICE   \n",
      "25588       SANTIAGO,  JOSE A         FIRE COMMISSIONER            FIRE   \n",
      "763    ANDOLINO,  ROSEMARIE S  COMMISSIONER OF AVIATION        AVIATION   \n",
      "4697     CHOUCAIR,  BECHARA N    COMMISSIONER OF HEALTH          HEALTH   \n",
      "\n",
      "       salary  rank_dept  \n",
      "18039  260004          1  \n",
      "8004   216210          1  \n",
      "25588  202728          1  \n",
      "763    186576          1  \n",
      "4697   177156          1  \n"
     ]
    }
   ],
   "source": [
    "df_chicago['rank_dept'] = df_chicago.groupby('department')['salary'].rank(method='first', ascending=False)\n",
    "df_chicago.sort('salary', ascending=False, inplace=True)\n",
    "print df_chicago[df_chicago['rank_dept'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge\n",
    "\n",
    "Use the **`pandas.merge()`** static method to merge/join datasets in a [relational](http://en.wikipedia.org/wiki/Relational_database) manner. (See [DOC](http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging))<br>\n",
    "Like SQL's JOIN clause, `pandas.merge()` allows two DataFrames to be joined on one or more keys.\n",
    "\n",
    "- parameter **`how`** : specify which keys are to be included in the resulting table\n",
    "- parameters **`on, left_on, right_on, left_index, right_index`** : to specify the columns or indexes on which to join.\n",
    "\n",
    "> `how` : {\"inner\", \"left\", \"right\", \"outer\"}\n",
    "\n",
    ">    * \"left\" : use keys from left frame only\n",
    ">    * \"right\" : use keys from right frame only\n",
    ">    * \"inner\" (default) : use intersection of keys from both frames\n",
    ">    * \"outer\" : use union of keys from both frames\n",
    "\n",
    "There are several cases to consider which are very important to understand:\n",
    "- **one-to-one** joins: to define these relationships, only one table is necessary (no join)\n",
    "    - one user **has** one phone number\n",
    "    - one phone number **belongs to** one user\n",
    "- **one-to-many** joins: to define these relationships, two tables are necessary \n",
    "    - one post **has** many comments\n",
    "    - one comment **belongs to** one post\n",
    "        - merge(left, right, on=['key'], how='?')\n",
    "- **many-to-many** joins: to define these relationships, three tables are necessary\n",
    "    - one playlist **has** many songs\n",
    "    - one song **belongs to** many playlists\n",
    "        - merge(left.reset_index(), right.reset_index(), on=['key'], how='?').set_index(['key_left','key_right'])\n",
    "\n",
    "Below are the different joins in SQL.\n",
    "\n",
    "![joins](http://i.stack.imgur.com/VQ5XP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value\n",
      "0    0         L0\n",
      "1    1         L1\n",
      "2    2         L2\n",
      "3    3         L3\n",
      "4    4         L4 \n",
      "\n",
      "   key right_value\n",
      "0    2          R0\n",
      "1    3          R1\n",
      "2    4          R2\n",
      "3    5          R3\n",
      "4    6          R4\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': range(5), \n",
    "                           'left_value': ['L0', 'L1', 'L2', 'L3', 'L4']})\n",
    "right = pd.DataFrame({'key': range(2, 7), \n",
    "                           'right_value': ['R0', 'R1', 'R2', 'R3', 'R4']})\n",
    "print left, '\\n'\n",
    "print right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Inner Join (default)\n",
    "Selects the rows from both tables with matching keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    2         L2          R0\n",
      "1    3         L3          R1\n",
      "2    4         L4          R2\n"
     ]
    }
   ],
   "source": [
    "print pd.merge(left, right, on='key', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If our key columns had *different names*, we could have used the **`left_on`** and **`right_on`** parameters to specify which fields to join from each frame.\n",
    "```python\n",
    "    pd.merge(left, right, left_on='left_key', right_on='right_key')\n",
    "```\n",
    "* If our key columns were *indexes*, we could use the **`left_index`** or **`right_index`** parameters to specify to use the index column, with a True/False value. You can mix and match columns and indexes like so:\n",
    "```python\n",
    "    pd.merge(left, right, left_on='key', right_index=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Left Outer Join\n",
    "Returns all rows from the left frame, with the matching rows in the right frame. The result is `NULL` in the right side when there is no match (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    0         L0         NaN\n",
      "1    1         L1         NaN\n",
      "2    2         L2          R0\n",
      "3    3         L3          R1\n",
      "4    4         L4          R2\n"
     ]
    }
   ],
   "source": [
    "print pd.merge(left, right, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Right Outer Join\n",
    "Returns all rows from the right frame, with the matching rows in the left frame. The result is NULL in the left side when there is no match (NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    2         L2          R0\n",
      "1    3         L3          R1\n",
      "2    4         L4          R2\n",
      "3    5        NaN          R3\n",
      "4    6        NaN          R4\n"
     ]
    }
   ],
   "source": [
    "print pd.merge(left, right, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Full Outer Join\n",
    "Combines the result of both Left Outer Join et Right Outer Join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key left_value right_value\n",
      "0    0         L0         NaN\n",
      "1    1         L1         NaN\n",
      "2    2         L2          R0\n",
      "3    3         L3          R1\n",
      "4    4         L4          R2\n",
      "5    5        NaN          R3\n",
      "6    6        NaN          R4\n"
     ]
    }
   ],
   "source": [
    "print pd.merge(left, right, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Concatenate\n",
    "\n",
    "Use pandas **`.concat()`** static method to combine Series/DataFrames into one unified object. (See [DOC](http://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-objects))\n",
    "\n",
    "`pandas.concat()` takes a list of Series or DataFrames and returns a Series or DataFrame of the concatenated objects. Note that because the function takes list, you can combine many objects at once.\n",
    "\n",
    "Use `axis` parameter to define along which axis to concatenate:\n",
    ">    `axis` = 0 : concatenate vertically (default)<br>\n",
    ">    `axis` = 1 : concatenante side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>left_value</th>\n",
       "      <th>key</th>\n",
       "      <th>right_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>L0</td>\n",
       "      <td>2</td>\n",
       "      <td>R0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>L2</td>\n",
       "      <td>4</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>L3</td>\n",
       "      <td>5</td>\n",
       "      <td>R3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>L4</td>\n",
       "      <td>6</td>\n",
       "      <td>R4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key left_value  key right_value\n",
       "0    0         L0    2          R0\n",
       "1    1         L1    3          R1\n",
       "2    2         L2    4          R2\n",
       "3    3         L3    5          R3\n",
       "4    4         L4    6          R4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([left, right], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Other\n",
    "\n",
    "### a) Rename columns\n",
    "\n",
    "Use `.rename()` method to change columns names.\n",
    "\n",
    "ex: df.rename(columns={'old_col_name' : 'new_col_name'}, inplace = True)\n",
    "\n",
    ">- columns : dictionnary containing the transformations to apply\n",
    ">- inplace (False) : result is a new instance of DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Handling Missing Values\n",
    "\n",
    "#### Drop missing values\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html<br>\n",
    "Use `.dropna()` method to drop rows or columns with missing data (NaN).\n",
    "\n",
    "ex: `df.dropna()`\n",
    "\n",
    ">- axis {(0), 1} : drop rows/columns\n",
    ">- subset (None) : list of columns/rows to consider \n",
    ">- inplace (False) : result is a new instance of DataFrame\n",
    "\n",
    "\n",
    "#### Fill missing values\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html<br>\n",
    "Use `.fillna()` method to drop rows or columns with missing data (NaN).\n",
    "\n",
    "ex: `df['col_A'].fillna(df['col_A'].mean())`\n",
    "\n",
    ">- value : value to use to fill holes\n",
    ">- method {'backfill', 'bfill', 'pad', 'ffill', (None)} : method of propagation to use for filling holes\n",
    ">- inplace (False) : result is a new instance of DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
